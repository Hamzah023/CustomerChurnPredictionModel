Combined Interview
SQL PowerBI
python, pandas, powerquery


sql:
indexes - fast way to look up rows that match the query 
ex: CREATE INDEX idx_salary ON Employees(Salary);


tables a way to organize data with rows and columns
ex: CREATE TABLE Employees (
    Employee_ID INT PRIMARY KEY,
    First_Name VARCHAR(50),
    Last_Name VARCHAR(50),
    Department VARCHAR(50),
    Salary DECIMAL(10, 2)
);


views a virtual table that you can create using the select statement, its readable and efficient, doesnt store data, read only, can join tables
ex: CREATE VIEW EmployeeView AS
SELECT First_Name, Last_Name, Department
FROM Employees
WHERE Salary > 50000;


stored procedures functions that hold repeatable sql queries, loops and conditionals
ex: CREATE PROCEDURE GetEmployeeDetails(IN emp_id INT)
BEGIN
    SELECT First_Name, Last_Name, Department, Salary
    FROM Employees
    WHERE Employee_ID = emp_id;
END;


left join - all records from left table and matching from right

right join - all records from right table and matching from left

inner join - only matching records from both
ex: SELECT table1.column_name, table2.column_name
FROM table1
INNER JOIN table2 ON table1.common_column = table2.common_column;


full outer join - all the records from both tables including matching

sql copy into command:
COPY INTO <target_table>
FROM <source_location>
FILE_FORMAT = (TYPE = <file_format_type>);

ex:

import snowflake.connector

# Establish connection to Snowflake
conn = snowflake.connector.connect(
    user='<your_user>',
    password='<your_password>',
    account='<your_account>',
    warehouse='<your_warehouse>',
    database='<your_database>',
    schema='<your_schema>'
)

# Create a cursor object to interact with the database
cursor = conn.cursor()

# Example: Copy data into Snowflake from an S3 bucket
copy_command = """
COPY INTO <target_table>
FROM 's3://<your_bucket>/<your_file>.csv'
CREDENTIALS = (AWS_KEY_ID = '<your_aws_access_key>' AWS_SECRET_KEY = '<your_aws_secret_key>')
FILE_FORMAT = (TYPE = 'CSV' FIELD_OPTIONALLY_ENCLOSED_BY = '"')
"""

# Execute the COPY INTO command
cursor.execute(copy_command)

# Close the cursor and connection
cursor.close()
conn.close()


SMOTE Summary
* Purpose: SMOTE Â (Synthetic Minority Oversampling Technique) is used to handle class imbalance by generating synthetic samples for the minority class.
* How It Works:
    1. Identify Neighbors: For each minority class sample, SMOTE selects its nearest neighbors using K-Nearest Neighbors (KNN).
    2. Generate Synthetic Samples: It randomly chooses one of the neighbors and generates a new data point along the line connecting them using interpolation.
    3. Balance the Dataset: The process repeats until the minority class has a comparable number of samples to the majority class.
* Formula:SyntheticÂ Point=A+Î»â‹…(Bâˆ’A)\text{Synthetic Point} = A + \lambda \cdot (B - A)SyntheticÂ Point=A+Î»â‹…(Bâˆ’A)
    * AAA = Minority class sample
    * BBB = One of its nearest neighbors
    * Î»\lambdaÎ» = Random number between 0 and 1
* Advantages:
    * Prevents overfitting compared to simple oversampling.
    * Improves model performance on imbalanced data.
    * Retains diversity in the minority class using interpolation instead of duplication.
* Use Case: Ideal for tasks like customer churn prediction, fraud detection, and other imbalanced datasets.


SMOTE (Synthetic Minority Oversampling Technique) is a popular technique used to address class imbalance in datasets, particularly in binary classification problems like churn prediction. Here's how it works in your case:
1. Identify Minority Class: In your dataset, the "Churn = Yes" class is the minority class (fewer samples compared to "Churn = No").
2. K-Nearest Neighbors (k-NN): For each sample in the minority class, SMOTE identifies its k-nearest neighbors within the same class. These neighbors are determined based on a distance metric (e.g., Euclidean distance).
3. Synthetic Sample Generation: SMOTE randomly selects one of the k-nearest neighbors and creates a synthetic sample. The synthetic sample is generated by interpolating between the original sample and the selected neighbor. This interpolation is done by taking a weighted average of the two samples, where the weights are determined by a random value between 0 and 1.
4. Add Synthetic Samples: The synthetic samples are added to the dataset, increasing the number of minority class samples and balancing the dataset.
By doing this, SMOTE effectively increases the representation of the minority class ("Churn = Yes") without simply duplicating existing samples. Instead, it generates new, plausible samples that lie along the line segments connecting existing samples in the feature space. This helps the model learn better decision boundaries and reduces the risk of overfitting.


HOW SMOTE WORKS:

the df is split into X (features) and y (target), and then SMOTE is applied to balance the dataset. Here's how SMOTE works and how it determines the number of samples to generate:

How SMOTE Works
Identify the Minority Class:

SMOTE first identifies the minority class in the target variable y. In your case, Churn_Yes = 1 is the minority class.
Determine the Number of Samples to Generate:

SMOTE calculates how many synthetic samples need to be generated to balance the dataset. For example:
If the majority class (Churn_Yes = 0) has 5164 samples and the minority class (Churn_Yes = 1) has 1857 samples, SMOTE will generate 5164 - 1857 = 3307 synthetic samples for the minority class.
Generate Synthetic Samples:

For each sample in the minority class, SMOTE selects one of its k-nearest neighbors (default k=5) in the feature space.
A synthetic sample is created by interpolating between the original sample and the selected neighbor. This interpolation is done by:
Taking a random value between 0 and 1.
Creating a new sample along the line segment connecting the original sample and its neighbor.
Add Synthetic Samples:

The synthetic samples are added to the dataset, resulting in a balanced dataset where both classes have the same number of samples.
How SMOTE Knows to Stop at 5164
SMOTE automatically balances the dataset by default. It ensures that the minority class (Churn_Yes = 1) has the same number of samples as the majority class (Churn_Yes = 0).
In your case:
The majority class (Churn_Yes = 0) has 5164 samples.
SMOTE generates enough synthetic samples for the minority class (Churn_Yes = 1) to also reach 5164 samples.
This behavior is controlled by the sampling_strategy parameter in SMOTE:
By default, sampling_strategy='auto', which means SMOTE will balance the dataset by making the minority class equal to the majority class.
You can customize this behavior by specifying a different sampling_strategy (e.g., 0.5 to make the minority class 50% of the majority class).
Example of How SMOTE Works in Your Code
Original Dataset:

Majority class (Churn_Yes = 0): 5164 samples.
Minority class (Churn_Yes = 1): 1857 samples.
SMOTE Calculation:

SMOTE calculates the difference: 5164 - 1857 = 3307.
It generates 3307 synthetic samples for the minority class.
Resulting Dataset:

After applying SMOTE:
Majority class (Churn_Yes = 0): 5164 samples.
Minority class (Churn_Yes = 1): 5164 samples.
The dataset is now balanced.
Key Parameters in SMOTE
random_state=42: Ensures reproducibility by fixing the random seed.
k_neighbors=5: Determines how many neighbors to consider when generating synthetic samples. You can adjust this to control how SMOTE interpolates between samples.
sampling_strategy: Controls the target ratio of the minority class. By default, it balances the dataset.
Why SMOTE Stops at 5164
SMOTE stops generating synthetic samples once the minority class matches the size of the majority class (5164 in this case).
This is the default behavior of SMOTE with sampling_strategy='auto'.

The data cleaning process Stats

Missing Values in TotalCharges:

Initially, there were 11 missing values in the TotalCharges column.
These were handled by converting the column to numeric and filling missing values with the median.
Afterward, there were no missing values in TotalCharges.
Categorical Encoding:

Categorical columns were identified and successfully one-hot encoded.
Redundant columns like gender_Male, Churn_No, and Partner_No were dropped.
Scaling:

Columns tenure, MonthlyCharges, and TotalCharges were scaled using MinMaxScaler.
Duplicates:

22 duplicate rows were identified and removed.
Class Imbalance:

SMOTE was applied to balance the Churn_Yes column, achieving a 50:50 class ratio.
Output Files:

The cleaned dataset was saved as cleaned_telco_data.csv.
The balanced dataset was saved as balanced_telco_data.csv.

Why collumns were dropped after one hot encoding:

The columns gender_Male and Partner_No were considered redundant because they are part of one-hot encoded categorical variables. When one-hot encoding is applied, each category in a categorical column is converted into a separate binary column. For example:

For the gender column, one-hot encoding creates two columns: gender_Male and gender_Female.
For the Partner column, one-hot encoding creates two columns: Partner_Yes and Partner_No.
In such cases, one of the columns is redundant because the information it provides can be inferred from the other column. For instance:

If gender_Female is 1, then gender_Male must be 0, and vice versa.
If Partner_Yes is 1, then Partner_No must be 0, and vice versa.
To avoid multicollinearity and reduce the dimensionality of the dataset, one of the columns is dropped. This is a common practice in machine learning preprocessing. In this case:

gender_Male was dropped, leaving only gender_Female.
Partner_No was dropped, leaving only Partner_Yes.
This ensures that the dataset remains interpretable and avoids redundancy without losing any information.


Psycopg is the most popular PostgreSQL database adapter for the Python programming language. Its main features are the complete implementation of the Python DB API 2.0 specification and the thread safety (several threads can share the same connection). 
It was designed for heavily multi-threaded applications that create and destroy lots of cursors and make a large number of concurrent â€œINSERTâ€s or â€œUPDATEâ€s.

How does minmax scaling work?

Min-Max Scaling, also known as Normalization, is a technique used to rescale the values of numeric features so they lie within a specific range, typically between 0 and 1. 
This is especially useful in machine learning algorithms that are sensitive to the scale of the data, such as neural networks and gradient-based algorithms.

How Min-Max Scaling Works:
The general formula for Min-Max scaling is:

ð‘‹
â€²
=
ð‘‹
âˆ’
ð‘‹
min
ð‘‹
max
âˆ’
ð‘‹
min
X 
â€²
 = 
X 
max
â€‹
 âˆ’X 
min
â€‹
 
Xâˆ’X 
min
â€‹
 
â€‹
 
Where:

ð‘‹
X is the original data point,
ð‘‹
min
X 
min
â€‹
  is the minimum value in the feature (column),
ð‘‹
max
X 
max
â€‹
  is the maximum value in the feature (column),
ð‘‹
â€²
X 
â€²
  is the scaled data point (normalized value).
Explanation:
The min value from the dataset becomes 0 after scaling.
The max value from the dataset becomes 1 after scaling.
All other values are proportionally adjusted within this range of [0, 1].
Example:
Suppose we have the following data in a column:

csharp
Copy
Edit
[10, 20, 30, 40, 50]
Minimum value (X_min) = 10
Maximum value (X_max) = 50
We apply the formula to scale a value (let's take 30 as an example):

ð‘‹
â€²
=
30
âˆ’
10
50
âˆ’
10
=
20
40
=
0.5
X 
â€²
 = 
50âˆ’10
30âˆ’10
â€‹
 = 
40
20
â€‹
 =0.5
So, the scaled value for 30 is 0.5.

Benefits of Min-Max Scaling:
It transforms features to a common scale, making it easier for algorithms to learn effectively.
It doesn't distort the distribution of the data (it preserves the relationship between values).
Potential Pitfalls:
If there are outliers in the data, they can distort the scaling process, as the minimum and maximum values will be affected by extreme values. For example, if the dataset contains a value of 1000, the scaling for all the other values will be compressed to a very small range near 0.
To handle this, other scaling methods like Robust Scaling or Standardization might be preferred if outliers are a concern.

In summary, Min-Max scaling transforms your data to fit within a specific range, helping algorithms perform better by ensuring that no feature dominates due to its scale.



#Cool advanced ML or statistic techniques:
- min max scaling
- hot one encoding
- SMOTE (Synthetic Minority Oversampling Technique)


1. Upload Your Data to Power BI Service
Log in to Power BI Service.
Go to My Workspace > + New > Upload a File.
Upload the cleaned_telco_data.xlsx or balanced_telco_data.xlsx file.
Power BI will create a dataset from the uploaded file.
2. Create a Report
After uploading the dataset, click on the dataset name (e.g., balanced_telco_data).
This will open the Report Editor.
3. Create Cool Graphs
Here are some ideas for visualizations you can create:

Graph 1: Churn Rate by Tenure (Bar Chart)
Purpose: Show how churn rate varies across different tenure ranges.
Steps:
Drag tenure to the X-axis.
Drag Churn_Yes to the Y-axis.
Change the visualization type to Clustered Bar Chart.
Apply a filter to show only Churn_Yes = 1 (churned customers).
Graph 2: Monthly Charges vs. Churn (Scatter Plot)
Purpose: Analyze the relationship between monthly charges and churn.
Steps:
Drag MonthlyCharges to the X-axis.
Drag tenure to the Y-axis.
Drag Churn_Yes to the Legend.
Change the visualization type to Scatter Chart.
Customize the colors to make churned customers stand out.
Graph 3: Churn Distribution (Pie Chart)
Purpose: Show the percentage of customers who churned vs. retained.
Steps:
Drag Churn_Yes to the Values field.
Change the visualization type to Pie Chart.
Customize the chart colors to differentiate churned and retained customers.
Graph 4: Revenue by Contract Type (Stacked Column Chart)
Purpose: Compare revenue across different contract types.
Steps:
Drag Contract to the X-axis.
Drag MonthlyCharges to the Y-axis.
Change the visualization type to Stacked Column Chart.
Add Churn_Yes to the Legend to break down revenue by churn status.
Graph 5: Churn Rate by Payment Method (Tree Map)
Purpose: Visualize churn rates across different payment methods.
Steps:
Drag PaymentMethod to the Group field.
Drag Churn_Yes to the Values field.
Change the visualization type to Tree Map.
4. Customize Your Graphs
Add Titles: Click on the graph and go to the Format Pane > Title to add a meaningful title.
Apply Filters: Use the Filters Pane to filter data (e.g., show only churned customers).
Add Slicers: Add slicers for fields like Contract, PaymentMethod, or tenure to make the dashboard interactive.
5. Save and Share
Save your report by clicking File > Save and give it a name (e.g., Telco Churn Report).
Pin visualizations to a dashboard:
Hover over a graph and click the Pin icon.
Choose an existing dashboard or create a new one.
Share the dashboard:
Go to the dashboard and click Share.
Enter the email addresses of the people you want to share it with.
6. Example Graphs
Hereâ€™s what your graphs might look like:

Bar Chart: Tenure vs. Churn Rate
Scatter Plot: Monthly Charges vs. Tenure (colored by churn)
Pie Chart: Churned vs. Retained Customers
Tree Map: Churn Rate by Payment Method


The confusion matrix and classification report you provided indicate the performance of your churn prediction model. Here's how to interpret the results:

1. Confusion Matrix
The confusion matrix is:
[[840 194]
 [136 896]]

Rows: Represent the actual classes (0 = No Churn, 1 = Churn).
Columns: Represent the predicted classes (0 = No Churn, 1 = Churn).
Predicted No Churn (0)	Predicted Churn (1)
Actual No Churn (0)	840	194
Actual Churn (1)	136	896


Key Metrics from the Confusion Matrix:
True Positives (TP): 896
Customers who actually churned and were correctly predicted as churned.
True Negatives (TN): 840
Customers who did not churn and were correctly predicted as not churned.
False Positives (FP): 194
Customers who did not churn but were incorrectly predicted as churned.
False Negatives (FN): 136
Customers who churned but were incorrectly predicted as not churned.


2. Classification Report
The classification report provides detailed metrics for each class (0 = No Churn, 1 = Churn):

Metric	Class 0 (No Churn)	Class 1 (Churn)	Macro Avg	Weighted Avg
Precision	0.86	0.82	0.84	0.84
Recall	0.81	0.87	0.84	0.84
F1-Score	0.84	0.84	0.84	0.84
Support	1034	1032	-	-


Key Metrics:
Precision:
Precision for Class 1 (Churn) = 0.82
This means that 82% of the customers predicted as churned were actually churned.
Precision for Class 0 (No Churn) = 0.86
This means that 86% of the customers predicted as not churned were actually not churned.
Recall:

Recall for Class 1 (Churn) = 0.87
This means that 87% of the actual churned customers were correctly identified by the model.
Recall for Class 0 (No Churn) = 0.81
This means that 81% of the actual non-churned customers were correctly identified by the model.
F1-Score:

F1-Score for Class 1 (Churn) = 0.84
This is the harmonic mean of precision and recall for churned customers.
F1-Score for Class 0 (No Churn) = 0.84
This is the harmonic mean of precision and recall for non-churned customers.
Accuracy:

Overall accuracy = 0.84 (84%)
This means that 84% of the predictions (both churned and non-churned) were correct.


3. Insights
The model performs well overall, with an accuracy of 84%.
The precision and recall for both classes are balanced, which is good for a churn prediction model.
The false positives (194) and false negatives (136) are relatively low, but you may want to focus on reducing false negatives (customers who churned but were predicted as not churned) since retaining churned customers is often a business priority.

